{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf11c188-54db-4488-bb26-ee309119fb69",
   "metadata": {},
   "source": [
    "1. IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae76165-e3a7-4134-abe1-f21f75438efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd #data processing \n",
    "import numpy as np #numerical computing \n",
    "from numpy import array\n",
    "import re #string manipulation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146f7f6c-60b1-428f-b92c-4b08ac4fd35f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: joblib in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1abb7b6d-07f7-43e8-931a-85b9a91a07f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk #NlP \n",
    "from nltk.corpus import stopwords # a list of common stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d359399-2d89-4140-a1c4-0def9a73b12c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.1)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (67.6.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\1\\uoa_py_course\\course_venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8133dd0b-acf6-4796-970b-5ab1c41a5331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #deploying artificial neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf6106c8-7e21-4656-b9cf-2bdbcc986bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #plots and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ced36059-7e02-4645-bc6b-67e84b865a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot, Tokenizer #one_hot function to convert text data into binary matrix representation where each word is a unique index\n",
    "                                                        #tokenizer class for indexing words in a text corpus\n",
    "from keras.models import Sequential #feedforward neural networks\n",
    "from keras.layers import Activation, Dropout, Dense # Activation function to the output of the previous layer \n",
    "                                                    #Dropout layer for prevent overfitting\n",
    "                                                 # Dense layer means each neuron in the layer is connected to every neuron in the previous and next layer.fully connected\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Embedding  #LSTM layer is a type of recurrent layer that is capable of learning long-term dependencies in sequential data\n",
    "                                                                #SimpleRNN is  a basic recurrent layer that can capture short-term dependencies in sequential data.\n",
    "                                                                #Embedding layer for converting integer indices representing words into dense vectors of fixed size. \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f24eb14f-6953-4bec-ae0c-eec86a53bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #split dataset into training and testing data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "246cc7c4-b3bf-47eb-a4c4-4caf78832f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences #pad_sequences is used to ensure that all sequences have the same length by padding shorter sequences with zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b304c4-4142-4910-94ed-0247db0bb84e",
   "metadata": {},
   "source": [
    "2.LOAD DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d207034-06bb-4c55-b38c-00b0f4e0d6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv ('IMDB Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc25e7f1-e45f-4f84-936f-8bb7f883896a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca446f73-31b8-48cf-b1a4-46657556f404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape   #number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "715a3370-5ada-473f-a019-a046b4a38a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # 2 columns object data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "446df62d-b591-48fc-97a5-0e11dfe80d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing value? False\n"
     ]
    }
   ],
   "source": [
    "print (\"Any missing value?\", df.isnull().values.any()) #check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99dd5739-dc46-4a7d-bba0-b349d96724b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_df= df.duplicated ().any "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ebb19e-2800-46cb-8b61-4ee67caa6fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are they any duplicated values? <bound method NDFrame._add_numeric_operations.<locals>.any of 0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "49995    False\n",
      "49996    False\n",
      "49997    False\n",
      "49998    False\n",
      "49999    False\n",
      "Length: 50000, dtype: bool>\n"
     ]
    }
   ],
   "source": [
    "print (\"Are they any duplicated values?\", dup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ab698d-e9ec-49e5-bf21-4ebaeb79bca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all') #overall statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "397b446f-a277-47ff-bb0f-83a7e8711d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so this series kind of takes the route of 'here we go again!' Week in, week out David Morse's character helps out his ride who is in a bit of a pickle - but what's wrong with that!? David Morse is one of the greatest character actors out there, and certainly the coolest, and to have him in a series created by David Koepp - a great writer - is heaven!!<br /><br />Due to the lack of love for this show by many, I can't see it going to a season series - but you never know? The amount of rubbish that has made it beyond that baffles me - let's hope something good can make it past a first series!!!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][38] #Example of a data point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed861532-646b-4e9f-b106-1e207f41023a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd6affc-178f-4a92-9657-933b97900cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts() #checking for imbalances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf7459-546a-4e02-ab9b-430828dc46bf",
   "metadata": {},
   "source": [
    "3.DATA CLEANING AND PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d8a58c2-5eb3-4651-8589-39b81ef5c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for word in r:\n",
    "        input_txt = re.sub(word, \"\", input_txt)\n",
    "    return input_txt\n",
    "\n",
    "\n",
    "df['review'] = np.vectorize(remove_pattern)(df['review'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4e4c8d8-5569-4f59-b942-d53abaa2ddb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "225160d3-3959-463c-b1a3-ecd000e43ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') #Setting English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fe66b9d-ef09-4cb5-837c-98709e7babab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'would', 'shall', 'could', 'might']\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "029e7efe-37c1-406a-a16a-162fcaaeace8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "new_stopwords = [\"would\", \"shall\", \"could\", \"might\"] # Define a list of new stopwords to add to the default list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07ed9b1a-5f7c-4d99-a187-2e674f7d311a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words.extend(new_stopwords) # Extend the default stopwords list with the new stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc1b5bbc-cca0-4ea8-8cce-a9a424d089e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words.remove(\"not\") #remove \"not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31090e2e-42bb-4356-ac16-9b3036ed28c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
